// This file is part of Substrate.

// Copyright (C) 2022 Parity Technologies (UK) Ltd.
// SPDX-License-Identifier: Apache-2.0

// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! Autogenerated weights for storage
//!
//! THIS FILE WAS AUTO-GENERATED USING THE SUBSTRATE BENCHMARK CLI VERSION 4.0.0-dev
//! DATE: 2023-11-07, STEPS: `50`, REPEAT: 20, LOW RANGE: `[]`, HIGH RANGE: `[]`
//! EXECUTION: Some(Wasm), WASM-EXECUTION: Compiled, CHAIN: Some("prod-test"), DB CACHE: 1024

// Executed Command:
// ./scripts/../target/release/joystream-node
// benchmark
// pallet
// --pallet=storage
// --extrinsic=*
// --chain=prod-test
// --steps=50
// --repeat=20
// --execution=wasm
// --template=./scripts/../devops/joystream-pallet-weight-template.hbs
// --output=./scripts/../runtime-modules/storage/src/weights.rs

#![cfg_attr(rustfmt, rustfmt_skip)]
#![allow(unused_parens)]
#![allow(unused_imports)]
#![allow(unused_variables)]

use frame_support::{traits::Get, weights::Weight};
use sp_std::marker::PhantomData;

/// Weight functions needed for storage.
pub trait WeightInfo {
	fn delete_storage_bucket() -> Weight;
	fn update_uploading_blocked_status() -> Weight;
	fn update_data_size_fee() -> Weight;
	fn update_storage_buckets_per_bag_limit() -> Weight;
	fn update_storage_buckets_voucher_max_limits() -> Weight;
	fn update_data_object_state_bloat_bond() -> Weight;
	fn update_number_of_storage_buckets_in_dynamic_bag_creation_policy() -> Weight;
	fn update_blacklist(_i: u32, _j: u32, ) -> Weight;
	fn create_storage_bucket() -> Weight;
	fn update_storage_buckets_for_bag(_i: u32, _j: u32, ) -> Weight;
	fn cancel_storage_bucket_operator_invite() -> Weight;
	fn invite_storage_bucket_operator() -> Weight;
	fn remove_storage_bucket_operator() -> Weight;
	fn update_storage_bucket_status() -> Weight;
	fn set_storage_bucket_voucher_limits() -> Weight;
	fn accept_storage_bucket_invitation() -> Weight;
	fn set_storage_operator_metadata(_i: u32, ) -> Weight;
	fn accept_pending_data_objects(_i: u32, ) -> Weight;
	fn create_distribution_bucket_family() -> Weight;
	fn delete_distribution_bucket_family() -> Weight;
	fn create_distribution_bucket() -> Weight;
	fn update_distribution_bucket_status() -> Weight;
	fn delete_distribution_bucket() -> Weight;
	fn update_distribution_buckets_for_bag(_i: u32, _j: u32, ) -> Weight;
	fn update_distribution_buckets_per_bag_limit() -> Weight;
	fn update_distribution_bucket_mode() -> Weight;
	fn update_families_in_dynamic_bag_creation_policy(_i: u32, ) -> Weight;
	fn invite_distribution_bucket_operator() -> Weight;
	fn cancel_distribution_bucket_operator_invite() -> Weight;
	fn remove_distribution_bucket_operator() -> Weight;
	fn set_distribution_bucket_family_metadata(_i: u32, ) -> Weight;
	fn accept_distribution_bucket_invitation() -> Weight;
	fn set_distribution_operator_metadata(_i: u32, ) -> Weight;
	fn storage_operator_remark(_i: u32, ) -> Weight;
	fn distribution_operator_remark(_i: u32, ) -> Weight;
}

/// Weights for storage using the Substrate node and recommended hardware.
pub struct SubstrateWeight<T>(PhantomData<T>);
impl<T: frame_system::Config> WeightInfo for SubstrateWeight<T> {
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage StorageBucketById (r:1 w:1)
	// Proof: Storage StorageBucketById (max_values: None, max_size: Some(106), added: 2581, mode: MaxEncodedLen)
	fn delete_storage_bucket() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `634`
		//  Estimated: `8704`
		// Minimum execution time: 28_250 nanoseconds.
		Weight::from_parts(29_580_000, 0u64)
			.saturating_add(Weight::from_parts(0, 8704))
			.saturating_add(T::DbWeight::get().reads(3_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage UploadingBlocked (r:0 w:1)
	// Proof: Storage UploadingBlocked (max_values: Some(1), max_size: Some(1), added: 496, mode: MaxEncodedLen)
	fn update_uploading_blocked_status() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `405`
		//  Estimated: `5133`
		// Minimum execution time: 21_644 nanoseconds.
		Weight::from_parts(22_123_000, 0u64)
			.saturating_add(Weight::from_parts(0, 5133))
			.saturating_add(T::DbWeight::get().reads(2_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DataObjectPerMegabyteFee (r:0 w:1)
	// Proof: Storage DataObjectPerMegabyteFee (max_values: Some(1), max_size: Some(16), added: 511, mode: MaxEncodedLen)
	fn update_data_size_fee() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `405`
		//  Estimated: `5133`
		// Minimum execution time: 21_901 nanoseconds.
		Weight::from_parts(22_444_000, 0u64)
			.saturating_add(Weight::from_parts(0, 5133))
			.saturating_add(T::DbWeight::get().reads(2_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage StorageBucketsPerBagLimit (r:0 w:1)
	// Proof: Storage StorageBucketsPerBagLimit (max_values: Some(1), max_size: Some(4), added: 499, mode: MaxEncodedLen)
	fn update_storage_buckets_per_bag_limit() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `405`
		//  Estimated: `5133`
		// Minimum execution time: 21_414 nanoseconds.
		Weight::from_parts(22_834_000, 0u64)
			.saturating_add(Weight::from_parts(0, 5133))
			.saturating_add(T::DbWeight::get().reads(2_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage VoucherMaxObjectsSizeLimit (r:0 w:1)
	// Proof: Storage VoucherMaxObjectsSizeLimit (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Storage VoucherMaxObjectsNumberLimit (r:0 w:1)
	// Proof: Storage VoucherMaxObjectsNumberLimit (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	fn update_storage_buckets_voucher_max_limits() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `405`
		//  Estimated: `5133`
		// Minimum execution time: 22_544 nanoseconds.
		Weight::from_parts(23_826_000, 0u64)
			.saturating_add(Weight::from_parts(0, 5133))
			.saturating_add(T::DbWeight::get().reads(2_u64))
			.saturating_add(T::DbWeight::get().writes(2_u64))
	}
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DataObjectStateBloatBondValue (r:0 w:1)
	// Proof: Storage DataObjectStateBloatBondValue (max_values: Some(1), max_size: Some(16), added: 511, mode: MaxEncodedLen)
	fn update_data_object_state_bloat_bond() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `405`
		//  Estimated: `5133`
		// Minimum execution time: 21_724 nanoseconds.
		Weight::from_parts(22_606_000, 0u64)
			.saturating_add(Weight::from_parts(0, 5133))
			.saturating_add(T::DbWeight::get().reads(2_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DynamicBagCreationPolicies (r:1 w:1)
	// Proof: Storage DynamicBagCreationPolicies (max_values: None, max_size: Some(634), added: 3109, mode: MaxEncodedLen)
	fn update_number_of_storage_buckets_in_dynamic_bag_creation_policy() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `518`
		//  Estimated: `9232`
		// Minimum execution time: 25_844 nanoseconds.
		Weight::from_parts(27_226_000, 0u64)
			.saturating_add(Weight::from_parts(0, 9232))
			.saturating_add(T::DbWeight::get().reads(3_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage Blacklist (r:2000 w:1000)
	// Proof: Storage Blacklist (max_values: None, max_size: Some(63), added: 2538, mode: MaxEncodedLen)
	// Storage: Storage CurrentBlacklistSize (r:1 w:1)
	// Proof: Storage CurrentBlacklistSize (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	/// The range of component `i` is `[0, 1000]`.
	/// The range of component `j` is `[0, 1000]`.
	fn update_blacklist(i: u32, j: u32, ) -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `545`
		//  Estimated: `7616 + i * (2538 ±0) + j * (2538 ±0)`
		// Minimum execution time: 1_864_200 nanoseconds.
		Weight::from_parts(1_875_446_000, 0u64)
			.saturating_add(Weight::from_parts(0, 7616))
			// Standard Error: 22_457
			.saturating_add(Weight::from_parts(2_899_287, 0u64).saturating_mul(i.into()))
			// Standard Error: 22_457
			.saturating_add(Weight::from_parts(646_593, 0u64).saturating_mul(j.into()))
			.saturating_add(T::DbWeight::get().reads(3_u64))
			.saturating_add(T::DbWeight::get().reads((1_u64).saturating_mul(i.into())))
			.saturating_add(T::DbWeight::get().reads((1_u64).saturating_mul(j.into())))
			.saturating_add(T::DbWeight::get().writes(1_u64))
			.saturating_add(T::DbWeight::get().writes((1_u64).saturating_mul(i.into())))
			.saturating_add(Weight::from_parts(0, 2538).saturating_mul(i.into()))
			.saturating_add(Weight::from_parts(0, 2538).saturating_mul(j.into()))
	}
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage VoucherMaxObjectsSizeLimit (r:1 w:0)
	// Proof: Storage VoucherMaxObjectsSizeLimit (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Storage VoucherMaxObjectsNumberLimit (r:1 w:0)
	// Proof: Storage VoucherMaxObjectsNumberLimit (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Storage NextStorageBucketId (r:1 w:1)
	// Proof: Storage NextStorageBucketId (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Storage StorageBucketById (r:0 w:1)
	// Proof: Storage StorageBucketById (max_values: None, max_size: Some(106), added: 2581, mode: MaxEncodedLen)
	fn create_storage_bucket() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `521`
		//  Estimated: `9612`
		// Minimum execution time: 29_761 nanoseconds.
		Weight::from_parts(31_002_000, 0u64)
			.saturating_add(Weight::from_parts(0, 9612))
			.saturating_add(T::DbWeight::get().reads(5_u64))
			.saturating_add(T::DbWeight::get().writes(2_u64))
	}
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage Bags (r:1 w:1)
	// Proof: Storage Bags (max_values: None, max_size: Some(964), added: 3439, mode: MaxEncodedLen)
	// Storage: Storage StorageBucketsPerBagLimit (r:1 w:0)
	// Proof: Storage StorageBucketsPerBagLimit (max_values: Some(1), max_size: Some(4), added: 499, mode: MaxEncodedLen)
	// Storage: Storage StorageBucketById (r:26 w:26)
	// Proof: Storage StorageBucketById (max_values: None, max_size: Some(106), added: 2581, mode: MaxEncodedLen)
	/// The range of component `i` is `[1, 13]`.
	/// The range of component `j` is `[1, 13]`.
	fn update_storage_buckets_for_bag(i: u32, j: u32, ) -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `635 + i * (73 ±0) + j * (81 ±0)`
		//  Estimated: `12041 + i * (2581 ±0) + j * (2581 ±0)`
		// Minimum execution time: 227_609 nanoseconds.
		Weight::from_parts(41_036_350, 0u64)
			.saturating_add(Weight::from_parts(0, 12041))
			// Standard Error: 23_573
			.saturating_add(Weight::from_parts(15_050_989, 0u64).saturating_mul(i.into()))
			// Standard Error: 23_573
			.saturating_add(Weight::from_parts(13_560_682, 0u64).saturating_mul(j.into()))
			.saturating_add(T::DbWeight::get().reads(4_u64))
			.saturating_add(T::DbWeight::get().reads((1_u64).saturating_mul(i.into())))
			.saturating_add(T::DbWeight::get().reads((1_u64).saturating_mul(j.into())))
			.saturating_add(T::DbWeight::get().writes(1_u64))
			.saturating_add(T::DbWeight::get().writes((1_u64).saturating_mul(i.into())))
			.saturating_add(T::DbWeight::get().writes((1_u64).saturating_mul(j.into())))
			.saturating_add(Weight::from_parts(0, 2581).saturating_mul(i.into()))
			.saturating_add(Weight::from_parts(0, 2581).saturating_mul(j.into()))
	}
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage StorageBucketById (r:1 w:1)
	// Proof: Storage StorageBucketById (max_values: None, max_size: Some(106), added: 2581, mode: MaxEncodedLen)
	fn cancel_storage_bucket_operator_invite() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `679`
		//  Estimated: `8704`
		// Minimum execution time: 30_562 nanoseconds.
		Weight::from_parts(31_738_000, 0u64)
			.saturating_add(Weight::from_parts(0, 8704))
			.saturating_add(T::DbWeight::get().reads(3_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:2 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage StorageBucketById (r:1 w:1)
	// Proof: Storage StorageBucketById (max_values: None, max_size: Some(106), added: 2581, mode: MaxEncodedLen)
	fn invite_storage_bucket_operator() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `800`
		//  Estimated: `11354`
		// Minimum execution time: 34_115 nanoseconds.
		Weight::from_parts(35_214_000, 0u64)
			.saturating_add(Weight::from_parts(0, 11354))
			.saturating_add(T::DbWeight::get().reads(4_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage StorageBucketById (r:1 w:1)
	// Proof: Storage StorageBucketById (max_values: None, max_size: Some(106), added: 2581, mode: MaxEncodedLen)
	fn remove_storage_bucket_operator() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `712`
		//  Estimated: `8704`
		// Minimum execution time: 30_814 nanoseconds.
		Weight::from_parts(31_912_000, 0u64)
			.saturating_add(Weight::from_parts(0, 8704))
			.saturating_add(T::DbWeight::get().reads(3_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage StorageBucketById (r:1 w:1)
	// Proof: Storage StorageBucketById (max_values: None, max_size: Some(106), added: 2581, mode: MaxEncodedLen)
	fn update_storage_bucket_status() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `634`
		//  Estimated: `8704`
		// Minimum execution time: 28_699 nanoseconds.
		Weight::from_parts(29_371_000, 0u64)
			.saturating_add(Weight::from_parts(0, 8704))
			.saturating_add(T::DbWeight::get().reads(3_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance2WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance2WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage StorageBucketById (r:1 w:1)
	// Proof: Storage StorageBucketById (max_values: None, max_size: Some(106), added: 2581, mode: MaxEncodedLen)
	// Storage: Storage VoucherMaxObjectsSizeLimit (r:1 w:0)
	// Proof: Storage VoucherMaxObjectsSizeLimit (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Storage VoucherMaxObjectsNumberLimit (r:1 w:0)
	// Proof: Storage VoucherMaxObjectsNumberLimit (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	fn set_storage_bucket_voucher_limits() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `692`
		//  Estimated: `11690`
		// Minimum execution time: 32_613 nanoseconds.
		Weight::from_parts(33_928_000, 0u64)
			.saturating_add(Weight::from_parts(0, 11690))
			.saturating_add(T::DbWeight::get().reads(5_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage StorageBucketById (r:1 w:1)
	// Proof: Storage StorageBucketById (max_values: None, max_size: Some(106), added: 2581, mode: MaxEncodedLen)
	fn accept_storage_bucket_invitation() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `679`
		//  Estimated: `7211`
		// Minimum execution time: 29_533 nanoseconds.
		Weight::from_parts(30_542_000, 0u64)
			.saturating_add(Weight::from_parts(0, 7211))
			.saturating_add(T::DbWeight::get().reads(2_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage StorageBucketById (r:1 w:0)
	// Proof: Storage StorageBucketById (max_values: None, max_size: Some(106), added: 2581, mode: MaxEncodedLen)
	/// The range of component `i` is `[1, 1000]`.
	fn set_storage_operator_metadata(i: u32, ) -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `712`
		//  Estimated: `7211`
		// Minimum execution time: 29_453 nanoseconds.
		Weight::from_parts(16_205_898, 0u64)
			.saturating_add(Weight::from_parts(0, 7211))
			// Standard Error: 1_368
			.saturating_add(Weight::from_parts(1_110_650, 0u64).saturating_mul(i.into()))
			.saturating_add(T::DbWeight::get().reads(2_u64))
	}
	// Storage: Storage StorageBucketById (r:1 w:0)
	// Proof: Storage StorageBucketById (max_values: None, max_size: Some(106), added: 2581, mode: MaxEncodedLen)
	// Storage: Storage Bags (r:1 w:0)
	// Proof: Storage Bags (max_values: None, max_size: Some(964), added: 3439, mode: MaxEncodedLen)
	// Storage: Storage DataObjectsById (r:400 w:400)
	// Proof: Storage DataObjectsById (max_values: None, max_size: Some(155), added: 2630, mode: MaxEncodedLen)
	/// The range of component `i` is `[1, 400]`.
	fn accept_pending_data_objects(i: u32, ) -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `419 + i * (104 ±0)`
		//  Estimated: `8990 + i * (2630 ±0)`
		// Minimum execution time: 38_120 nanoseconds.
		Weight::from_parts(38_662_000, 0u64)
			.saturating_add(Weight::from_parts(0, 8990))
			// Standard Error: 36_011
			.saturating_add(Weight::from_parts(11_664_089, 0u64).saturating_mul(i.into()))
			.saturating_add(T::DbWeight::get().reads(2_u64))
			.saturating_add(T::DbWeight::get().reads((1_u64).saturating_mul(i.into())))
			.saturating_add(T::DbWeight::get().writes((1_u64).saturating_mul(i.into())))
			.saturating_add(Weight::from_parts(0, 2630).saturating_mul(i.into()))
	}
	// Storage: Instance9WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance9WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketFamilyNumber (r:1 w:1)
	// Proof: Storage DistributionBucketFamilyNumber (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Storage NextDistributionBucketFamilyId (r:1 w:1)
	// Proof: Storage NextDistributionBucketFamilyId (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketFamilyById (r:0 w:1)
	// Proof: Storage DistributionBucketFamilyById (max_values: None, max_size: Some(32), added: 2507, mode: MaxEncodedLen)
	fn create_distribution_bucket_family() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `485`
		//  Estimated: `8119`
		// Minimum execution time: 28_671 nanoseconds.
		Weight::from_parts(29_337_000, 0u64)
			.saturating_add(Weight::from_parts(0, 8119))
			.saturating_add(T::DbWeight::get().reads(4_u64))
			.saturating_add(T::DbWeight::get().writes(3_u64))
	}
	// Storage: Instance9WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance9WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketFamilyById (r:1 w:1)
	// Proof: Storage DistributionBucketFamilyById (max_values: None, max_size: Some(32), added: 2507, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketByFamilyIdById (r:1 w:0)
	// Proof: Storage DistributionBucketByFamilyIdById (max_values: None, max_size: Some(380), added: 2855, mode: MaxEncodedLen)
	// Storage: Storage DynamicBagCreationPolicies (r:2 w:0)
	// Proof: Storage DynamicBagCreationPolicies (max_values: None, max_size: Some(634), added: 3109, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketFamilyNumber (r:1 w:1)
	// Proof: Storage DistributionBucketFamilyNumber (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	fn delete_distribution_bucket_family() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `596`
		//  Estimated: `21176`
		// Minimum execution time: 39_967 nanoseconds.
		Weight::from_parts(41_453_000, 0u64)
			.saturating_add(Weight::from_parts(0, 21176))
			.saturating_add(T::DbWeight::get().reads(7_u64))
			.saturating_add(T::DbWeight::get().writes(2_u64))
	}
	// Storage: Instance9WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance9WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketFamilyById (r:1 w:1)
	// Proof: Storage DistributionBucketFamilyById (max_values: None, max_size: Some(32), added: 2507, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketByFamilyIdById (r:0 w:1)
	// Proof: Storage DistributionBucketByFamilyIdById (max_values: None, max_size: Some(380), added: 2855, mode: MaxEncodedLen)
	fn create_distribution_bucket() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `577`
		//  Estimated: `8630`
		// Minimum execution time: 31_784 nanoseconds.
		Weight::from_parts(32_713_000, 0u64)
			.saturating_add(Weight::from_parts(0, 8630))
			.saturating_add(T::DbWeight::get().reads(3_u64))
			.saturating_add(T::DbWeight::get().writes(2_u64))
	}
	// Storage: Instance9WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance9WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketByFamilyIdById (r:1 w:1)
	// Proof: Storage DistributionBucketByFamilyIdById (max_values: None, max_size: Some(380), added: 2855, mode: MaxEncodedLen)
	fn update_distribution_bucket_status() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `639`
		//  Estimated: `8978`
		// Minimum execution time: 31_264 nanoseconds.
		Weight::from_parts(32_484_000, 0u64)
			.saturating_add(Weight::from_parts(0, 8978))
			.saturating_add(T::DbWeight::get().reads(3_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance9WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance9WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketByFamilyIdById (r:1 w:1)
	// Proof: Storage DistributionBucketByFamilyIdById (max_values: None, max_size: Some(380), added: 2855, mode: MaxEncodedLen)
	fn delete_distribution_bucket() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `639`
		//  Estimated: `8978`
		// Minimum execution time: 30_730 nanoseconds.
		Weight::from_parts(32_093_000, 0u64)
			.saturating_add(Weight::from_parts(0, 8978))
			.saturating_add(T::DbWeight::get().reads(3_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance9WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance9WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage Bags (r:1 w:1)
	// Proof: Storage Bags (max_values: None, max_size: Some(964), added: 3439, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketFamilyById (r:1 w:0)
	// Proof: Storage DistributionBucketFamilyById (max_values: None, max_size: Some(32), added: 2507, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketsPerBagLimit (r:1 w:0)
	// Proof: Storage DistributionBucketsPerBagLimit (max_values: Some(1), max_size: Some(4), added: 499, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketByFamilyIdById (r:102 w:102)
	// Proof: Storage DistributionBucketByFamilyIdById (max_values: None, max_size: Some(380), added: 2855, mode: MaxEncodedLen)
	/// The range of component `i` is `[1, 51]`.
	/// The range of component `j` is `[1, 51]`.
	fn update_distribution_buckets_for_bag(i: u32, j: u32, ) -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `681 + i * (41 ±0) + j * (57 ±0)`
		//  Estimated: `15538 + i * (2855 ±0) + j * (2855 ±0)`
		// Minimum execution time: 541_099 nanoseconds.
		Weight::from_parts(42_944_182, 0u64)
			.saturating_add(Weight::from_parts(0, 15538))
			// Standard Error: 22_016
			.saturating_add(Weight::from_parts(9_828_405, 0u64).saturating_mul(i.into()))
			// Standard Error: 22_016
			.saturating_add(Weight::from_parts(10_057_128, 0u64).saturating_mul(j.into()))
			.saturating_add(T::DbWeight::get().reads(5_u64))
			.saturating_add(T::DbWeight::get().reads((1_u64).saturating_mul(i.into())))
			.saturating_add(T::DbWeight::get().reads((1_u64).saturating_mul(j.into())))
			.saturating_add(T::DbWeight::get().writes(1_u64))
			.saturating_add(T::DbWeight::get().writes((1_u64).saturating_mul(i.into())))
			.saturating_add(T::DbWeight::get().writes((1_u64).saturating_mul(j.into())))
			.saturating_add(Weight::from_parts(0, 2855).saturating_mul(i.into()))
			.saturating_add(Weight::from_parts(0, 2855).saturating_mul(j.into()))
	}
	// Storage: Instance9WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance9WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketsPerBagLimit (r:0 w:1)
	// Proof: Storage DistributionBucketsPerBagLimit (max_values: Some(1), max_size: Some(4), added: 499, mode: MaxEncodedLen)
	fn update_distribution_buckets_per_bag_limit() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `372`
		//  Estimated: `5133`
		// Minimum execution time: 21_344 nanoseconds.
		Weight::from_parts(22_186_000, 0u64)
			.saturating_add(Weight::from_parts(0, 5133))
			.saturating_add(T::DbWeight::get().reads(2_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance9WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance9WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketByFamilyIdById (r:1 w:1)
	// Proof: Storage DistributionBucketByFamilyIdById (max_values: None, max_size: Some(380), added: 2855, mode: MaxEncodedLen)
	fn update_distribution_bucket_mode() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `639`
		//  Estimated: `8978`
		// Minimum execution time: 31_408 nanoseconds.
		Weight::from_parts(32_702_000, 0u64)
			.saturating_add(Weight::from_parts(0, 8978))
			.saturating_add(T::DbWeight::get().reads(3_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance9WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance9WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketFamilyById (r:7 w:0)
	// Proof: Storage DistributionBucketFamilyById (max_values: None, max_size: Some(32), added: 2507, mode: MaxEncodedLen)
	// Storage: Storage DynamicBagCreationPolicies (r:1 w:1)
	// Proof: Storage DynamicBagCreationPolicies (max_values: None, max_size: Some(634), added: 3109, mode: MaxEncodedLen)
	/// The range of component `i` is `[2, 7]`.
	fn update_families_in_dynamic_bag_creation_policy(i: u32, ) -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `545 + i * (36 ±0)`
		//  Estimated: `10222 + i * (2507 ±0)`
		// Minimum execution time: 36_540 nanoseconds.
		Weight::from_parts(29_817_203, 0u64)
			.saturating_add(Weight::from_parts(0, 10222))
			// Standard Error: 21_027
			.saturating_add(Weight::from_parts(4_428_774, 0u64).saturating_mul(i.into()))
			.saturating_add(T::DbWeight::get().reads(3_u64))
			.saturating_add(T::DbWeight::get().reads((1_u64).saturating_mul(i.into())))
			.saturating_add(T::DbWeight::get().writes(1_u64))
			.saturating_add(Weight::from_parts(0, 2507).saturating_mul(i.into()))
	}
	// Storage: Instance9WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance9WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance9WorkingGroup WorkerById (r:2 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketByFamilyIdById (r:1 w:1)
	// Proof: Storage DistributionBucketByFamilyIdById (max_values: None, max_size: Some(380), added: 2855, mode: MaxEncodedLen)
	fn invite_distribution_bucket_operator() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `805`
		//  Estimated: `11628`
		// Minimum execution time: 36_905 nanoseconds.
		Weight::from_parts(38_637_000, 0u64)
			.saturating_add(Weight::from_parts(0, 11628))
			.saturating_add(T::DbWeight::get().reads(4_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance9WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance9WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketByFamilyIdById (r:1 w:1)
	// Proof: Storage DistributionBucketByFamilyIdById (max_values: None, max_size: Some(380), added: 2855, mode: MaxEncodedLen)
	fn cancel_distribution_bucket_operator_invite() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `684`
		//  Estimated: `8978`
		// Minimum execution time: 35_132 nanoseconds.
		Weight::from_parts(35_884_000, 0u64)
			.saturating_add(Weight::from_parts(0, 8978))
			.saturating_add(T::DbWeight::get().reads(3_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance9WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance9WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketByFamilyIdById (r:1 w:1)
	// Proof: Storage DistributionBucketByFamilyIdById (max_values: None, max_size: Some(380), added: 2855, mode: MaxEncodedLen)
	fn remove_distribution_bucket_operator() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `684`
		//  Estimated: `8978`
		// Minimum execution time: 34_479 nanoseconds.
		Weight::from_parts(35_685_000, 0u64)
			.saturating_add(Weight::from_parts(0, 8978))
			.saturating_add(T::DbWeight::get().reads(3_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance9WorkingGroup CurrentLead (r:1 w:0)
	// Proof: Instance9WorkingGroup CurrentLead (max_values: Some(1), max_size: Some(8), added: 503, mode: MaxEncodedLen)
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketFamilyById (r:1 w:0)
	// Proof: Storage DistributionBucketFamilyById (max_values: None, max_size: Some(32), added: 2507, mode: MaxEncodedLen)
	/// The range of component `i` is `[1, 1000]`.
	fn set_distribution_bucket_family_metadata(i: u32, ) -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `577`
		//  Estimated: `8630`
		// Minimum execution time: 28_188 nanoseconds.
		Weight::from_parts(14_830_031, 0u64)
			.saturating_add(Weight::from_parts(0, 8630))
			// Standard Error: 1_407
			.saturating_add(Weight::from_parts(1_109_384, 0u64).saturating_mul(i.into()))
			.saturating_add(T::DbWeight::get().reads(3_u64))
	}
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketByFamilyIdById (r:1 w:1)
	// Proof: Storage DistributionBucketByFamilyIdById (max_values: None, max_size: Some(380), added: 2855, mode: MaxEncodedLen)
	fn accept_distribution_bucket_invitation() -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `684`
		//  Estimated: `7485`
		// Minimum execution time: 33_094 nanoseconds.
		Weight::from_parts(34_415_000, 0u64)
			.saturating_add(Weight::from_parts(0, 7485))
			.saturating_add(T::DbWeight::get().reads(2_u64))
			.saturating_add(T::DbWeight::get().writes(1_u64))
	}
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketByFamilyIdById (r:1 w:0)
	// Proof: Storage DistributionBucketByFamilyIdById (max_values: None, max_size: Some(380), added: 2855, mode: MaxEncodedLen)
	/// The range of component `i` is `[1, 1000]`.
	fn set_distribution_operator_metadata(i: u32, ) -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `684`
		//  Estimated: `7485`
		// Minimum execution time: 31_392 nanoseconds.
		Weight::from_parts(16_692_338, 0u64)
			.saturating_add(Weight::from_parts(0, 7485))
			// Standard Error: 1_496
			.saturating_add(Weight::from_parts(1_114_341, 0u64).saturating_mul(i.into()))
			.saturating_add(T::DbWeight::get().reads(2_u64))
	}
	// Storage: Instance2WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance2WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage StorageBucketById (r:1 w:0)
	// Proof: Storage StorageBucketById (max_values: None, max_size: Some(106), added: 2581, mode: MaxEncodedLen)
	/// The range of component `i` is `[1, 1000]`.
	fn storage_operator_remark(i: u32, ) -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `712`
		//  Estimated: `7211`
		// Minimum execution time: 29_223 nanoseconds.
		Weight::from_parts(9_584_685, 0u64)
			.saturating_add(Weight::from_parts(0, 7211))
			// Standard Error: 1_719
			.saturating_add(Weight::from_parts(1_130_073, 0u64).saturating_mul(i.into()))
			.saturating_add(T::DbWeight::get().reads(2_u64))
	}
	// Storage: Instance9WorkingGroup WorkerById (r:1 w:0)
	// Proof: Instance9WorkingGroup WorkerById (max_values: None, max_size: Some(175), added: 2650, mode: MaxEncodedLen)
	// Storage: Storage DistributionBucketByFamilyIdById (r:1 w:0)
	// Proof: Storage DistributionBucketByFamilyIdById (max_values: None, max_size: Some(380), added: 2855, mode: MaxEncodedLen)
	/// The range of component `i` is `[1, 1000]`.
	fn distribution_operator_remark(i: u32, ) -> Weight {
		// Proof Size summary in bytes:
		//  Measured:  `684`
		//  Estimated: `7485`
		// Minimum execution time: 31_721 nanoseconds.
		Weight::from_parts(16_208_127, 0u64)
			.saturating_add(Weight::from_parts(0, 7485))
			// Standard Error: 1_540
			.saturating_add(Weight::from_parts(1_123_267, 0u64).saturating_mul(i.into()))
			.saturating_add(T::DbWeight::get().reads(2_u64))
	}
}

// Default implementation for tests
impl WeightInfo for () {
	fn delete_storage_bucket() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn update_uploading_blocked_status() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn update_data_size_fee() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn update_storage_buckets_per_bag_limit() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn update_storage_buckets_voucher_max_limits() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn update_data_object_state_bloat_bond() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn update_number_of_storage_buckets_in_dynamic_bag_creation_policy() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn update_blacklist(i: u32, j: u32, ) -> Weight {
		Weight::from_parts(0, 0)
	}
	fn create_storage_bucket() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn update_storage_buckets_for_bag(i: u32, j: u32, ) -> Weight {
		Weight::from_parts(0, 0)
	}
	fn cancel_storage_bucket_operator_invite() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn invite_storage_bucket_operator() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn remove_storage_bucket_operator() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn update_storage_bucket_status() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn set_storage_bucket_voucher_limits() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn accept_storage_bucket_invitation() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn set_storage_operator_metadata(i: u32, ) -> Weight {
		Weight::from_parts(0, 0)
	}
	fn accept_pending_data_objects(i: u32, ) -> Weight {
		Weight::from_parts(0, 0)
	}
	fn create_distribution_bucket_family() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn delete_distribution_bucket_family() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn create_distribution_bucket() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn update_distribution_bucket_status() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn delete_distribution_bucket() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn update_distribution_buckets_for_bag(i: u32, j: u32, ) -> Weight {
		Weight::from_parts(0, 0)
	}
	fn update_distribution_buckets_per_bag_limit() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn update_distribution_bucket_mode() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn update_families_in_dynamic_bag_creation_policy(i: u32, ) -> Weight {
		Weight::from_parts(0, 0)
	}
	fn invite_distribution_bucket_operator() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn cancel_distribution_bucket_operator_invite() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn remove_distribution_bucket_operator() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn set_distribution_bucket_family_metadata(i: u32, ) -> Weight {
		Weight::from_parts(0, 0)
	}
	fn accept_distribution_bucket_invitation() -> Weight {
		Weight::from_parts(0, 0)
	}
	fn set_distribution_operator_metadata(i: u32, ) -> Weight {
		Weight::from_parts(0, 0)
	}
	fn storage_operator_remark(i: u32, ) -> Weight {
		Weight::from_parts(0, 0)
	}
	fn distribution_operator_remark(i: u32, ) -> Weight {
		Weight::from_parts(0, 0)
	}
}
